{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nQQp4beZ3VaFP_u3ZHlzP-RU2oIIeRmJ",
      "authorship_tag": "ABX9TyMccsvYk751GS6BmlUWpUkI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakshith-kukyan/Samarthya/blob/main/object_detection_rcnn_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-object-detection-api"
      ],
      "metadata": {
        "id": "Yfeah8xE-Ebq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from object_detection import exporter\n",
        "from object_detection import model_lib_v2\n",
        "from object_detection.builders import model_builder"
      ],
      "metadata": {
        "id": "opvUHp789vOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biNkavcf8bs3"
      },
      "outputs": [],
      "source": [
        "model {\n",
        "  faster_rcnn {\n",
        "    num_classes: 90\n",
        "    image_resizer {\n",
        "      keep_aspect_ratio_resizer {\n",
        "        min_dimension: 800\n",
        "        max_dimension: 1333\n",
        "        pad_to_max_dimension: true\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'faster_rcnn_resnet101_keras'\n",
        "    }\n",
        "    first_stage_anchor_generator {\n",
        "      grid_anchor_generator {\n",
        "        scales: [0.25, 0.5, 1.0, 2.0]\n",
        "        aspect_ratios: [0.5, 1.0, 2.0]\n",
        "        height_stride: 16\n",
        "        width_stride: 16\n",
        "      }\n",
        "    }\n",
        "    first_stage_box_predictor_conv_hyperparams {\n",
        "      op: CONV\n",
        "      regularizer {\n",
        "        l2_regularizer {\n",
        "          weight: 0.0\n",
        "        }\n",
        "      }\n",
        "      initializer {\n",
        "        truncated_normal_initializer {\n",
        "          stddev: 0.01\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    first_stage_nms_score_threshold: 0.0\n",
        "    first_stage_nms_iou_threshold: 0.7\n",
        "    first_stage_max_proposals: 300\n",
        "    first_stage_localization_loss_weight: 2.0\n",
        "    first_stage_objectness_loss_weight: 1.0\n",
        "    initial_crop_size: 14\n",
        "    maxpool_kernel_size: 2\n",
        "    maxpool_stride: 2\n",
        "    second_stage_box_predictor {\n",
        "      mask_rcnn_box_predictor {\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 1.0\n",
        "        fc_hyperparams {\n",
        "          op: FC\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.0\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            variance_scaling_initializer {\n",
        "              factor: 1.0\n",
        "              uniform: true\n",
        "              mode: FAN_AVG\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    second_stage_post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 0.0\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 100\n",
        "      }\n",
        "      score_converter: SOFTMAX\n",
        "    }\n",
        "    second_stage_localization_loss_weight: 2.0\n",
        "    second_stage_classification_loss_weight: 1.0\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_config: {\n",
        "  batch_size: 16\n",
        "  num_steps: 200000\n",
        "  optimizer {\n",
        "    momentum_optimizer: {\n",
        "      learning_rate: {\n",
        "        cosine_decay_learning_rate {\n",
        "          learning_rate_base: 0.01\n",
        "          total_steps: 200000\n",
        "          warmup_learning_rate: 0.0\n",
        "          warmup_steps: 5000\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "    }\n",
        "    use_moving_average: false\n",
        "  }\n",
        "  gradient_clipping_by_norm: 10.0\n",
        "  fine_tune_checkpoint_version: V2\n",
        "  fine_tune_checkpoint: \"/content/MyDrive/resnet101.ckpt-1\"\n",
        "  fine_tune_checkpoint_type: \"classification\"\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "\n",
        "  data_augmentation_options {\n",
        "    random_adjust_hue {\n",
        "    }\n",
        "  }\n",
        "\n",
        "  data_augmentation_options {\n",
        "    random_adjust_contrast {\n",
        "    }\n",
        "  }\n",
        "\n",
        "  data_augmentation_options {\n",
        "    random_adjust_saturation {\n",
        "    }\n",
        "  }\n",
        "\n",
        "  data_augmentation_options {\n",
        "     random_square_crop_by_scale {\n",
        "      scale_min: 0.6\n",
        "      scale_max: 1.3\n",
        "    }\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "fotPFpE89G02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_reader: {\n",
        "  label_map_path: \"/content/drive/MyDrive/label_map.txt\"\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/drive/MyDrive/train2017-?????-of-00256.tfrecord\"\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "Zvf4ESZ68_KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_config: {\n",
        "  metrics_set: \"coco_detection_metrics\"\n",
        "  use_moving_averages: false\n",
        "  batch_size: 1;\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  label_map_path: \"/content/drive/MyDrive/label_map.txt\"\n",
        "  shuffle: false\n",
        "  num_epochs: 1\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/drive/MyDrive/COCO_2017/val2017-?????-of-00032.tfrecord\"\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "LTEzc77G88Bc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}